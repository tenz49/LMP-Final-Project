import os
import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score


# Step 1: Define your dataset class and apply transformations
class CollagenDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img_idx = idx // 100
        sub_idx = idx % 100
        image = Image.open(self.image_paths[img_idx])
        label = self.labels[img_idx]

        sub_width = image.width // 10
        sub_height = image.height // 10

        i = sub_idx % 10
        j = sub_idx // 10

        left = i * sub_width
        upper = j * sub_height
        right = left + sub_width
        lower = upper + sub_height

        image = image.crop((left, upper, right, lower))

        if self.transform:
            image = self.transform(image)
        return image, label

# Step 2: Load image paths and labels
image_folder = '/Users/sophia/Desktop/AFM image'
image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.png')])
image_paths = [os.path.join(image_folder, f) for f in image_files]
image_paths = np.repeat(image_paths, 100)
labels = np.concatenate([np.repeat(np.ones(50), 100), np.repeat(np.zeros(50), 100)])

# Step 3: Split your dataset
train_val_images, test_images, train_val_labels, test_labels = train_test_split(image_paths,
                                                                                labels,
                                                                                test_size=0.2,
                                                                                random_state=42)
train_images, val_images, train_labels, val_labels = train_test_split(train_val_images,
                                                                      train_val_labels,
                                                                      test_size=1 / 8,
                                                                      random_state=42)

# Step 4: Data resize and to tensor
transform_train = transforms.Compose([
    transforms.Resize((51, 51)),
    transforms.ToTensor(),
])

transform_test = transforms.Compose([
    transforms.Resize((51, 51)),
    transforms.ToTensor(),
])

# Step 5: Create dataset objects and data loaders
train_dataset = CollagenDataset(train_images, train_labels, transform=transform_train)
val_dataset = CollagenDataset(val_images, val_labels, transform=transform_test)
test_dataset = CollagenDataset(test_images, test_labels, transform=transform_test)

batch_size = 4
num_workers = 0
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

# Step 6: Load pre-trained VGG model
mps_device = torch.device("mps")
model = torchvision.models.vgg16(weights=None)
# Load the weights from the local file
weights_path = '/Users/sophia/Downloads/vgg16-397923af.pth'
model.load_state_dict(torch.load(weights_path))
# Freeze the first 6 layers
for i, layer in enumerate(model.features):
    if i >= 6:
        break
    for param in layer.parameters():
        param.requires_grad = False
# Change the last layer to output 2 classes
model.classifier[-1] = torch.nn.Linear(model.classifier[-1].in_features, 2)
model.to(mps_device)

# Step 7: Train the VGG model and obtain training accuracy
criterion = torch.nn.CrossEntropyLoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)

num_epochs = 100
train_accuracies, test_accuracies = [], []
precisions, recalls, f1_scores, aucs = [], [], [], []

for epoch in range(num_epochs):
    # Training
    model.train()
    correct = 0
    total = 0
    for images, labels in train_loader:
        images, labels = images.to(torch.float32).to(mps_device), labels.to(torch.float32).to(mps_device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, labels.long())
        loss.backward()
        optimizer.step()

        _, predicted = outputs.max(1)
        total += labels.size(0)
        correct += predicted.eq(labels).sum().item()

    train_acc = correct / total
    train_accuracies.append(train_acc)

    # Evaluation
    model.eval()
    correct = 0
    total = 0
    all_labels = []
    all_predictions = []
    with torch.no_grad():
        for images, labels in test_loader:
            images, labels = images.to(torch.float32).to(mps_device), labels.to(torch.float32).to(mps_device)

            outputs = model(images)
            loss = criterion(outputs, labels.long())

            _, predicted = outputs.max(1)
            total += labels.size(0)
            correct += predicted.eq(labels).sum().item()

            all_labels.extend(labels.cpu().numpy())
            all_predictions.extend(predicted.cpu().numpy())

    test_acc = correct / total
    test_accuracies.append(train_acc)

    precision = precision_score(all_labels, all_predictions)
    recall = recall_score(all_labels, all_predictions)
    f1 = f1_score(all_labels, all_predictions)
    auc = roc_auc_score(all_labels, all_predictions)

    precisions.append(precision)
    recalls.append(recall)
    f1_scores.append(f1)
    aucs.append(auc)

    print(f"Epoch {epoch + 1}/{num_epochs}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}")
    print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, AUC: {auc:.4f}")

# Step 8: Plot the results
epochs = range(1, num_epochs + 1)

plt.figure()
plt.plot(epochs, train_accuracies, label="Training Accuracy")
plt.plot(epochs, test_accuracies, label="Testing Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

plt.figure()
plt.plot(epochs, precisions, label="Precision")
plt.plot(epochs, recalls, label="Recall")
plt.plot(epochs, f1_scores, label="F1 Score")
plt.plot(epochs, aucs, label="AUC")
plt.xlabel("Epoch")
plt.ylabel("Score")
plt.legend()
plt.show()
